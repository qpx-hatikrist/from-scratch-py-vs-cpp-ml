## **RU :ru:**

# Сравнение моделей машинного обучения: свои реализации vs scikit-learn (C++ и Python)

Проект для экспериментального сравнения реализаций классических моделей машинного обучения в трёх вариантах:

1. **Библиотека `scikit-learn`** (baseline);
2. **Собственная реализация на Python**;
3. **Собственная реализация на C++**.

Сравнение ведётся по двум основным критериям:

- **качество модели** (ошибка / точность на тестовых данных);
- **производительность** (время обучения и предсказания).

В настоящий момент реализована и сравнивается **линейная регрессия**, **Ridge**, **Lasso**; остальные модели находятся в разработке.

---

## Цели проекта

- Получить практическое понимание того, насколько близко к `scikit-learn` можно подойти, реализуя модели «вручную».
- Исследовать разницу между Python и C++ при реализации одних и тех же алгоритмов:
  - накладные расходы языка и рантайма;
  - удобство разработки;
  - сложность поддержки кода.
- Построить воспроизводимые эксперименты, в которых можно:
  - запускать одинаковые сценарии обучения и тестирования;
  - фиксировать метрики качества;
  - проводить честные бенчмарки по времени.

---

## Архитектура и структура репозитория

```text
from-scratch-py-vs-cpp-ml/
├── data/                 # Исходные данные для экспериментов
│   └── regression/       # Датасеты для задач регрессии
├── notebooks/            # Jupyter-ноутбуки с экспериментами и визуализацией
├── src/                  # Реализации алгоритмов на C++ и Python
├── vendor/               # Внешний/вспомогательный код (заголовки, утилиты и пр.)
├── requirements.txt      # Python-зависимости
└── .gitmodules           # Конфигурация git-подмодулей
```

---

### Реализация метрик и предобработки

В рамках проекта мы **осознанно реализуем вручную** как основные метрики, так и предобработку данных:

**Метрики (Python и C++):**

- R²  
- D²  
- RMSE  
- SMAPE  
- RMSLE
- MAXE
- MedAE
- EVS

**Предобработка:**

- `StandardScaler` — собственная реализация стандартизации признаков (оценка среднего и стандартного отклонения по train-части, применение к train/test).
- `train_test_split` — собственная реализация разбиения выборки на train / test с фиксированным random seed и shuffle.


Цели такого подхода:

- лучше понимать численное поведение и возможные источники ошибок;
- сравнивать не только модели, но и стоимость вычисления метрик/преобразований в Python и C++;

При этом мы **сознательно используем `scikit-learn` только как утилиту анализа**:

- **`learning_curve`**  
- **`permutation_test_score`**

Эти функции берутся из `sklearn.model_selection` и используются для:

- построения кривых обучения и анализа обобщающей способности;
- оценки статистической значимости качества моделей.

Во всех экспериментальных ноутбуках явно указано, какие части пайплайна реализованы вручную, а какие используют `sklearn` как вспомогательный инструмент.

---

### Линейная регрессия

Оценка проводится **на одном и том же датасете** (пока что используем один датасет; в дальнейшем планируем добавить несколько разнородных наборов данных) по следующему набору метрик:

- **R²** — коэффициент детерминации;
- **D²** — модификация R² (deviance-based score) для оценки качества предсказаний;
- **RMSE** — вариация средней квадратичной ошибки (mean root square error);
- **MAXE** — максимальная абсолютная ошибка (наихудший промах модели по одному объекту);
- **MedAE** — медианная абсолютная ошибка (типичная ошибка, устойчива к выбросам);
- **EVS** — доля дисперсии целевой переменной, объяснённая моделью (насколько хорошо модель объясняет вариацию таргета).

Помимо точечных метрик, мы используем инструменты анализа обобщающей способности и статистической значимости:

- **`learning_curve`** — для построения кривых обучения и анализа зависимости качества от размера обучающей выборки;
- **`permutation_test_score`** — для оценки статистической значимости качества модели и проверки, не является ли результат следствием случайности.

| Stack          | RMSE      | R²       | D²       | MAXE        | MedAE       | EVS      | fit_time (s) | pred_time (s) |
|----------------|----------:|---------:|---------:|------------:|------------:|---------:|-------------:|--------------:|
| sklearn        | 21461.048 | 0.928407 | 0.739617 | 158451.5957 | 10961.87213 | 0.92844  | 0.0784       | 0.000679      |
| Python scratch | 21461.048 | 0.928407 | 0.739617 | 158451.5951 | 10961.87198 | 0.92844  | 39.340       | 0.050775      |
| C++ scratch    | *TBD*     | *TBD*    | *TBD*    | *TBD*       | *TBD*       | *TBD*    | *TBD*        | *TBD*         |

**Вывод (LinearRegression):** `ScratchLinearRegression` по качеству совпадает с `sklearn.LinearRegression` (различия на уровне машинной точности), что означает корректность реализации с математической точки зрения. Обучение примерно в **×500** раз медленнее, а предсказание — в **×70** раз медленнее из-за циклов на чистом Python.

*Более подробный анализ (кривые обучения, permutation test, сравнение метрик и реализаций) приведён в ноутбуке [`notebooks/linear_regression.ipynb`](notebooks/linear_regression.ipynb).*

---

### Ridge

| Impl           | RMSE      | R²       | D²       | MAXE        | MedAE       | EVS      | fit_time (s) | pred_time (s) |
|----------------|----------:|---------:|---------:|------------:|------------:|---------:|-------------:|--------------:|
| sklearn        | 21162.30  | 0.930386 | 0.744151 | 158372.79   | 10550.75    | 0.930414 | 0.025        | 0.002         |
| Python scratch | 21162.30  | 0.930386 | 0.744151 | 158372.79   | 10550.75    | 0.930414 | 38.08        | 0.051         |
| C++ scratch    | *TBD*     | *TBD*    | *TBD*    | *TBD*       | *TBD*       | *TBD*    | *TBD*        | *TBD*         |

**Вывод (Ridge):** моя реализация полностью совпадает со `sklearn.Ridge` по всем метрикам (разница в пределах машинной точности), но обучение в чистом Python ~**×1500** медленнее, а предсказание ~**×25** медленнее. Математика корректна, но по скорости это чисто учебная реализация.

*Более подробный анализ (кривые обучения, permutation test, сравнение метрик и реализаций) приведён в ноутбуке [`notebooks/linear_regression.ipynb`](notebooks/linear_regression.ipynb).*

---

### Lasso

| Impl           | RMSE      | R²       | D²       | MAXE        | MedAE       | EVS      | fit_time (s) | pred_time (s) |
|----------------|----------:|---------:|---------:|------------:|------------:|---------:|-------------:|--------------:|
| sklearn        | 20929.67  | 0.931908 | 0.752938 | 160524.52   | 10362.82    | 0.931929 | 0.089        | 0.00093       |
| Python scratch | 20928.15  | 0.931918 | 0.752961 | 160520.72   | 10361.59    | 0.931939 | 226.95       | 0.10144       |
| C++ scratch    | *TBD*     | *TBD*    | *TBD*    | *TBD*       | *TBD*       | *TBD*    | *TBD*        | *TBD*         |

**Вывод (Lasso):** `ScratchLasso` даёт почти те же значения RMSE, R², D², EVS, MAXE и MedAE, что и `sklearn.Lasso` (расхождения на 3–4 знак), то есть реализован корректно. Цена — время: обучение ~**×2500** медленнее, предсказание ~**×100** медленнее.

*Более подробный анализ (кривые обучения, permutation test, сравнение метрик и реализаций) приведён в ноутбуке [`notebooks/linear_regression.ipynb`](notebooks/linear_regression.ipynb).*